{
  "hash": "86468ac6af5327f562739ea8f995c209",
  "result": {
    "markdown": "---\ntitle: Missing data\nauthor: Liam D. Bailey\ndate: '2022-05-30'\ndescription: \"Dealing with NAs in a time-series\"\ncategories: [R, Climate Change, Statistics]\nimage: \"feature.png\"\n---\n\n\n## Introduction\n\n---\n\nA common problem we encounter when analysing data is the presence of missing data, NAs. How do we deal with NAs when we encounter them? In this blog post I'll focus on different methods for dealing with NAs in R, with a particular focus on climatic time series.\n\n## Preparing our workspace\n\n---\n\n### Packages\n\n---\n\nBelow are all the packages that we'll use in this example. Many of these are standard data science packages in R, but notice the inclusion of `{imputeTS}`, which is a tool specifically designed to deal with NAs in a time series.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow) #To (quickly) read csv files\nlibrary(dplyr) #For data wrangling\nlibrary(ggplot2) #For plotting\nlibrary(imputeTS) #To impute data in data pipelines\n```\n:::\n\n\n### Our example data\n\n---\n\nWe'll focus on a time series of temperature data from Melbourne, Australia (Source: [Australian Bureau of Meteorology](http://www.bom.gov.au/climate/data/)). This is actually a complete time series with no missing data, but we'll generate 400 NAs in the time series at random.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_data <- arrow::read_csv_arrow(file = \"data/melbourne_temp.csv\") %>% \n  mutate(date = lubridate::ymd(paste(Year, Month, Day)),\n         maxT_missing = maxT)\n\n#Generate some NAs in the data\n#We ensure that the last row can't become NA so that linear interpolation is always possible\nset.seed(321)\nfull_data$maxT_missing[sample(1:(nrow(full_data) - 1), size = 400)] <- NA\n```\n:::\n\n\n## Step 1: Visualize the missing data\n\n---\n\nThe first step to any analysis should be to inspect and visualize your data. Dealing with NAs is no different. If we know there are NAs in our time series we want to see when they occur and how often. `{imputeTS}` includes a number of in-built plotting functions to visualize NAs (e.g. `?imputeTS::ggplot_na_distribution`) but here I've used `{ggplot2}` to make a set of custom plots.\n\nFirst, we can look at which year the NAs occur in. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_data <- full_data %>% \n  group_by(Year) %>% \n  summarise(perc_NA = sum(is.na(maxT_missing))/n() * 100)\n\n#The limit of the y-axis will be the nearest declie above the data\nyaxis_lim <- (max(plot_data$perc_NA) %/% 10)*10 + 10\n\nggplot(data = plot_data) +\n  geom_col(aes(x = Year, y = perc_NA),\n           fill = \"indianred\", colour = \"black\",\n           linewidth = 0.25) +\n  # scale_fill_manual(values = c(\"steelblue\", \"indianred\"),\n                    # name = \"\", labels = c(\"Not NA\", \"Is NA\")) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(breaks = seq(0, 100, 5),\n                     labels = paste0(seq(0, 100, 5), \"%\")) +\n  coord_cartesian(ylim = c(0, yaxis_lim)) +\n  labs(title = \"Missing Values per Year\",\n       subtitle = \"Percentage of missing data in each year of the time-series\",\n       x = \"Year\", y = \"Percentage of records\") +\n  theme_classic() +\n  theme(panel.grid.major.y = element_line(colour = \"grey75\", linewidth = 0.25))\n```\n\n::: {.cell-output-display}\n![Percentage of missing data in each year of the time-series](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_line(data = full_data, aes(x = date, y = maxT_missing), colour = \"steelblue2\") +\n  geom_vline(data = filter(full_data, is.na(maxT_missing)), aes(xintercept = date),\n             colour = \"indianred\", alpha = 0.5) +\n  scale_x_date(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(title = \"Location of missing values\",\n       subtitle = \"Time series with highlighted missing regions\",\n       y = \"Temperature (C)\",\n       x = \"\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_data %>% \n  filter(Year == 2022) %>% \n  {ggplot() +\n      geom_line(data = ., aes(x = date, y = maxT_missing), colour = \"steelblue2\") +\n      geom_vline(data = filter(., is.na(maxT_missing)), aes(xintercept = date),\n                 colour = \"indianred\", alpha = 0.5) +\n      scale_x_date(expand = c(0, 0)) +\n      scale_y_continuous(expand = c(0, 0)) +\n      labs(title = \"Location of missing values\",\n           subtitle = \"Time series with highlighted missing regions\",\n           y = \"Temperature (C)\",\n           x = \"\") +\n      theme_classic()}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot_na_gapsize(full_data$maxT_missing)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## The basic method: Deletion\n\n---\n\nNAs include no information and cannot be used in statistical models. Therefore, the most common solution when encountering NAs is to simply delete them. This method is perfectly appropraite in many cases, but it can raise 2 key issues in any analysis:\n\n- Bias: If missing data are biased in some way, removing missing data will create bias in analysis. e.g. if temperature sensors tend to fail more at higher temperatures, removing NA values will bias our analysis towards lower temperatures.\n\n- Reduced statistical power: If we have many missing values, we will remove a lot of data and have lower statistical power to answer out questions.\n\nSo, what is the alternative? We can use imputation to fill in sampling periods where data are missing.\n\n## Method 1: Mean substitution\n\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_data <- full_data %>% \n  mutate(maxT_meansub = case_when(is.na(maxT_missing) ~ mean(maxT_missing, na.rm = TRUE),\n                                  TRUE ~ maxT_missing))\n```\n:::\n\n\nIssue here: reduces effect of multi-variate analysis because imputed values will *necessarily* not be unrelated to other variables used in analysis (because all imputations are the same despite other variables being different).\n\nAn extreme example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\neg_lmdata <- tibble(x = 1:100) %>% \n  mutate(y = x*0.5 + rnorm(n = 100))\n\neg_lmdata$y[sample(x = 1:nrow(eg_lmdata), size = 40)] <- NA\n\neg_lmdata <- eg_lmdata %>% \n  mutate(y_fill = case_when(is.na(y) ~ mean(y, na.rm = TRUE),\n                            TRUE ~ y))\n\nlm(y ~ x, data = eg_lmdata) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x, data = eg_lmdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6184 -0.7792  0.2352  0.7237  2.3373 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.049978   0.259576  -0.193    0.848    \nx            0.504576   0.004651 108.486   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.07 on 58 degrees of freedom\n  (40 observations deleted due to missingness)\nMultiple R-squared:  0.9951,\tAdjusted R-squared:  0.995 \nF-statistic: 1.177e+04 on 1 and 58 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(y_fill ~ x, data = eg_lmdata) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y_fill ~ x, data = eg_lmdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2250  -5.9340   0.0968   5.9225  15.8661 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   7.6047     1.4368   5.293 7.36e-07 ***\nx             0.3205     0.0247  12.977  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.13 on 98 degrees of freedom\nMultiple R-squared:  0.6321,\tAdjusted R-squared:  0.6284 \nF-statistic: 168.4 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nWe will often want to do more complex multi-variate analysis, so this mean imputation is generally not useful!!\n\n## Method 2: Linear imputation\n\n---\n\nIf we are focussing on multi-variate analysis we want a method that allows imputed values to vary. Linear imputation is one of the simplest methods to do this, especially when using time series data. We impute a missing value using a linear relationship between the points before and after the value itself.\n\nThis can be done using the 'approx' function in {stats}; however, this does not fit nicely within a {tidyverse} pipe coding. As an alternative, we can use the package {imputeTS}, which is a wrapper around basic {stats} functions (e.g. `approx`, `spline`) as well as other more complex imputation functions from other packages.\n\nHow does linear imputation work? [CREATE A GRAPH SHOWING THE IDEA!!]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputeTS::na_interpolation(x = c(1, NA, 3), option = \"linear\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Notice that it only uses information from the 2 closest values\nimputeTS::na_interpolation(x = c(4, 2, 1, NA, 3, 2, 7), option = \"linear\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4 2 1 2 3 2 7\n```\n:::\n:::\n\n\nIt will use a single linear model to estimate blocks of NAs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputeTS::na_interpolation(x = c(1, NA, NA, 4), option = \"linear\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3 4\n```\n:::\n:::\n\n\nInterprets blocks of NAs using the same linear model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_data <- full_data %>% \n  mutate(maxT_linearinterp = imputeTS::na_interpolation(x = maxT_missing, option = \"linear\"))\n```\n:::\n\n\nCompare real and interpolated values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(full_data, is.na(maxT_missing)) %>% \n  mutate(diff = maxT - maxT_linearinterp,\n         sign = diff > 0) %>%\n  {ggplot(.) +\n      geom_histogram(aes(x = diff), bins = 15, colour = \"black\", fill = \"grey75\") +\n      geom_vline(xintercept = median(.$diff), lty = 2) +\n      theme_classic() +\n      theme(legend.position = \"none\",\n            axis.text.y = element_blank(),\n            axis.title = element_blank(),\n            axis.ticks.y = element_blank(),\n            axis.line.y = element_blank())}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Method 2: Weighted mean\n\n---\n\nThe approx function has an alternative where it interpolates gaps using a weighted mean of the left and right values. We define method as 'constant' and then weighting using 'f'; where a value of 1 is fully right weighted (i.e. value will = the value on the right) and value of 0 is fully left weighted. Therefore, f = 0.5 is the same as taking the mean of the two nearest points.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputeTS::na_interpolation(x = c(1, NA, 3), option = \"linear\", method = \"constant\", f = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3\n```\n:::\n:::\n\n\nI guess this is a more sophisticated form of mean substitution, because all missing values in a *block* are given same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputeTS::na_interpolation(x = c(1, NA, NA, 4), option = \"linear\", method = \"constant\", f = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.0 2.5 2.5 4.0\n```\n:::\n:::\n\n\nThere may be cases where we would want to weight more towards the left or right, but this seems very niche!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_data <- full_data %>% \n  mutate(maxT_const = imputeTS::na_interpolation(x = maxT_missing, option = \"linear\", method = \"constant\", f = 0.5))\n```\n:::\n\n\nCompare real and interpolated values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(full_data, is.na(maxT_missing)) %>% \n  mutate(diff = maxT - maxT_const,\n         sign = diff > 0) %>%\n  {ggplot(.) +\n      geom_histogram(aes(x = diff), bins = 15, colour = \"black\", fill = \"grey75\") +\n      geom_vline(xintercept = median(.$diff), lty = 2) +\n      theme_classic() +\n      theme(legend.position = \"none\",\n            axis.text.y = element_blank(),\n            axis.title = element_blank(),\n            axis.ticks.y = element_blank(),\n            axis.line.y = element_blank())}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## Method 3: Spline interpolation\n\n---\n\nAnother from {stats}. We can use different spline functions to fill in gaps. Unlike linear interpolation, spline interpolation uses more data either side of missing value. Makes sense! Would be impossible to fit spline to 2 data points that would be anything but linear! In fact, I guess we can recreate linear by using spline on data with only 1 value either side.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#This is just the same as a linear model because the spline doesn't have any more detail\n#to form a more complex spline\nimputeTS::na_interpolation(x = c(1, NA, 3), option = \"spline\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Once we provide more data, imputation can fit a more complex spline\nimputeTS::na_interpolation(x = c(3, 2.5, 2, 1, NA, 0.75, 0, -0.5, -1), option = \"spline\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3.0000000  2.5000000  2.0000000  1.0000000  0.8142007  0.7500000  0.0000000\n[8] -0.5000000 -1.0000000\n```\n:::\n:::\n\n\nThere are 5 types of splines that we can use (need to study them more closely). However, for visual inspection we can also get the spline function back using `splinefun()` in {stats}.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Demonstrate how it works\ntest_df <- tibble(x = 1:9,\n                  y = c(3, 2.5, 2, 1, NA, 0.75, 0, -0.5, -1))\n\nfmm_func <- splinefun(x = test_df$y, method = \"fmm\")\nperiodic_func <- splinefun(x = test_df$y, method = \"periodic\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in splinefun(x = test_df$y, method = \"periodic\"): spline: first and\nlast y values differ - using y[1L] for both\n```\n:::\n\n```{.r .cell-code}\nnatural_func <- splinefun(x = test_df$y, method = \"natural\")\nmonoH.FC_func <- splinefun(x = test_df$y, method = \"monoH.FC\")\nhyman_func <- splinefun(x = test_df$y, method = \"hyman\")\n\nspline_df <- tibble(x = seq(1, 9, 0.1)) %>% \n  mutate(fmm = fmm_func(x = x),\n         periodic = periodic_func(x = x),\n         natural = natural_func(x = x),\n         monoH.FC = monoH.FC_func(x = x),\n         hyman = hyman_func(x = x)) %>% \n  tidyr::pivot_longer(cols = fmm:hyman, names_to = \"spline\", values_to = \"y\")\n\nggplot()+\n  geom_point(data = test_df, aes(x = x, y = y)) +\n  geom_line(data = spline_df, aes(x = x, y = y, lty = spline)) +\n  theme_classic()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n### Compare the different splines\n\n---\n\nFit all the different splines.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspline_data <- full_data %>% \n  mutate(maxT_fmm = imputeTS::na_interpolation(x = maxT_missing, option = \"spline\", method = \"fmm\"),\n         maxT_periodic = imputeTS::na_interpolation(x = maxT_missing, option = \"spline\", method = \"periodic\"),\n         maxT_natural = imputeTS::na_interpolation(x = maxT_missing, option = \"spline\", method = \"natural\"),\n         #NOTE: monoH and hyman both assume monotonic data (i.e. data should either never increase or decrease)\n         #This is not expected for temp data and (unsurprisingly) these spline methods fail\n         # maxT_monoH = imputeTS::na_interpolation(x = maxT_missing, option = \"spline\", method = \"monoH.FC\"),\n         # maxT_hyman = imputeTS::na_interpolation(x = maxT_missing, option = \"spline\", method = \"hyman\")\n  ) %>% \n  tidyr::pivot_longer(cols = maxT_fmm:maxT_natural, names_to = \"spline_method\", values_to = \"maxT_impute\")\n```\n:::\n\n\nCompare real and interpolated values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(spline_data, is.na(maxT_missing)) %>% \n  mutate(diff = maxT - maxT_impute,\n         sign = diff > 0) %>%\n  {ggplot(.) +\n      geom_histogram(aes(x = diff), bins = 15, colour = \"black\", fill = \"grey75\") +\n      geom_vline(xintercept = median(.$diff), lty = 2) +\n      facet_wrap(facets = ~spline_method) +\n      theme_classic() +\n      theme(legend.position = \"none\",\n            axis.text.y = element_blank(),\n            axis.title = element_blank(),\n            axis.ticks.y = element_blank(),\n            axis.line.y = element_blank())}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Method 4: Stineman imputation\n\n---\n\nFinal option is na_interpolation. Uses algorithm in Stineman 1980.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Here essentially still linear\nimputeTS::na_interpolation(x = c(1, NA, 3), option = \"stine\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3\n```\n:::\n:::\n\n\nI guess this is a more sophisticated form of mean substitution, because all missing values in a *block* are given same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputeTS::na_interpolation(x = c(3, 2.5, 2, 1, NA, 0.75, 0, -0.5, -1), option = \"stine\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3.000  2.500  2.000  1.000  0.875  0.750  0.000 -0.500 -1.000\n```\n:::\n:::\n\n\nThere may be cases where we would want to weight more towards the left or right, but this seems very niche!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_data <- full_data %>% \n  mutate(maxT_stine = imputeTS::na_interpolation(x = maxT_missing, option = \"stine\"))\n```\n:::\n\n\nCompare real and interpolated values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(full_data, is.na(maxT_missing)) %>% \n  mutate(diff = maxT - maxT_stine,\n         sign = diff > 0) %>%\n  {ggplot(.) +\n      geom_histogram(aes(x = diff), bins = 15, colour = \"black\", fill = \"grey75\") +\n      geom_vline(xintercept = median(.$diff), lty = 2) +\n      theme_classic() +\n      theme(legend.position = \"none\",\n            axis.text.y = element_blank(),\n            axis.title = element_blank(),\n            axis.ticks.y = element_blank(),\n            axis.line.y = element_blank())}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n## Method 5: Weighted moving average\n\n---\n\nLinear imputation or 'constant' option (from {stats} `approx()`) use just the adjacent values, but we can often benefit from using information from more nearby values. We can do this with a weighted moving average.\n\nKey arguments:\n\n- `k`: Size of the window to calculate moving average. NOTE: This is size to either side of the NA that will be used, \"this means for an NA value at position i of a time series, the observations i-1,i+1 and i+1, i+2 (assuming a window size of k=2) are used to calculate the mean.\" (from help).\n\n- `weighting`: Method to use for weighting values.\n- `simple`: All values are equally weighted\n- `linear`: Weight decreases linearly with distance from i. If x is the distance from i, then value has a weight 1/(1 + x), such that the nearest values have weight of 1/2, 1/3, 1/4 etc.\n- `exponential`: Weights decrease exponentially. If x is the distance from i, then value has a weight 1/2^x.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#This will be identical to using \"constant\" from `approx()` no matter what method we use!\n#We are only looking at the two nearest neighbours\nimputeTS::na_ma(x = c(3, 1, NA, 3, 10), k = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3  1  2  3 10\n```\n:::\n\n```{.r .cell-code}\nimputeTS::na_interpolation(x = c(3, 1, NA, 3, 10), option = \"linear\", method = \"constant\", f = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  3  1  2  3 10\n```\n:::\n:::\n\n\nAs we expand the window, we can get a more nuanced value. No longer the same as using 'constant'.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputeTS::na_ma(x = c(4, 3, 1, NA, 3, 4, 10), k = 3, weighting = \"simple\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  4.000000  3.000000  1.000000  4.166667  3.000000  4.000000 10.000000\n```\n:::\n:::\n\n\nCan use different methods to adjust weighting. Note above that 10 is having a large effect on the returned value even though it is 3 time steps away. We could use linear or exponential weighting to minimize this effect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputeTS::na_ma(x = c(4, 3, 1, NA, 3, 4, 10), k = 3, weighting = \"linear\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  4.000000  3.000000  1.000000  3.615385  3.000000  4.000000 10.000000\n```\n:::\n\n```{.r .cell-code}\nimputeTS::na_ma(x = c(4, 3, 1, NA, 3, 4, 10), k = 3, weighting = \"exponential\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  4.000000  3.000000  1.000000  3.142857  3.000000  4.000000 10.000000\n```\n:::\n:::\n\n\nCompare real and interpolated values for each weighting method. For now, we just use default window size k = 4 (i.e. using 8 values in total towards mean)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmovingavg_data <- full_data %>% \n  mutate(maxT_mas = imputeTS::na_ma(x = maxT_missing, weighting = \"simple\"),\n         maxT_mal = imputeTS::na_ma(x = maxT_missing, weighting = \"linear\"),\n         maxT_mae = imputeTS::na_ma(x = maxT_missing, weighting = \"exponential\")) %>%\n  filter(is.na(maxT_missing)) %>% \n  tibble::rowid_to_column() %>% \n  tidyr::pivot_longer(cols = maxT_mas:maxT_mae, names_to = \"weight_method\", values_to = \"maxT_impute\")\n\nfilter(movingavg_data) %>% \n  mutate(diff = maxT - maxT_impute,\n         sign = diff > 0) %>%\n  {ggplot(.) +\n      geom_histogram(aes(x = diff), bins = 15, colour = \"black\", fill = \"grey75\") +\n      geom_vline(xintercept = median(.$diff), lty = 2) +\n      facet_wrap(facets = ~weight_method) +\n      theme_classic() +\n      theme(legend.position = \"none\",\n            axis.text.y = element_blank(),\n            axis.title = element_blank(),\n            axis.ticks.y = element_blank(),\n            axis.line.y = element_blank())}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n## Overview: Use LOO-CV to look at effectiveness of different techniques\n\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLOO_impute <- function(fn, x, i, ...){\n  \n  if (i > length(x)) {\n    \n    i <- length(x)\n    \n    warning(\"i is larger than number of data points. i reduced to match length(x).\")\n    \n  }\n  \n  missing_index <- sample(1:length(x), size = i, replace = FALSE)\n  \n  results <- purrr::map_df(missing_index, .f = function(missing_index){\n    \n    #Assign to a new vector\n    x_missing <- x\n    #Give an NA\n    x_missing[missing_index] <- NA\n    \n    #Extract known value and imputed value\n    x_true <- x[missing_index]\n    x_imp  <- fn(x_missing, ...)[missing_index]\n    \n    tibble(true = x_true,\n           imputed = x_imp)\n    \n  })\n  \n  results %>% \n    mutate(diff = (imputed - true)^2) %>%\n    summarise(MSE = sum(diff)/n()) %>% \n    mutate(RMSE = sqrt(MSE))\n}\n```\n:::\n\n\nSo how do our different methods compare?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- tibble(method = c(\"linear_interp\",\n                             \"spline_fmm\",\n                             \"stine\",\n                             \"ma_simple\",\n                             \"ma_linear\",\n                             \"ma_expo\")) %>% \n  mutate(do.call(bind_rows,\n                 args = list(LOO_impute(fn = na_interpolation, i = 5000, x = full_data$maxT),\n                             LOO_impute(fn = na_interpolation, i = 5000, x = full_data$maxT, option = \"spline\", method = \"fmm\"),\n                             LOO_impute(fn = na_interpolation, i = 5000, x = full_data$maxT, option = \"stine\"),\n                             LOO_impute(fn = na_ma, i = 5000, x = full_data$maxT, weighting = \"simple\"),\n                             LOO_impute(fn = na_ma, i = 5000, x = full_data$maxT, weighting = \"linear\"),\n                             LOO_impute(fn = na_ma, i = 5000, x = full_data$maxT, weighting = \"exponential\"))))\n\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  method          MSE  RMSE\n  <chr>         <dbl> <dbl>\n1 linear_interp  12.4  3.52\n2 spline_fmm     14.2  3.77\n3 stine          11.5  3.39\n4 ma_simple      17.2  4.15\n5 ma_linear      15.6  3.95\n6 ma_expo        14.2  3.77\n```\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}